\documentclass[]{article}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\usepackage{matlab-prettifier}
\usepackage{array}
\usepackage{amsthm}
\usepackage{fullpage}

 \theoremstyle{theorem}
\newtheorem{structure}{Structure}%[section]


\graphicspath{ {images/} }
\usepackage{comment}

\setlength\parindent{0pt}

\title{Report: V{\small I}LMA}
\author{Jesus Miguel Adrian Matos}
\date{\today}


\begin{document}
\maketitle

\begin{abstract} 
\noindent This report is based on the seminar entitled {\it Visual grounding of verbs and nominalisations in multimodal models}, taken by Albert Gatt on May 29, 2024.
In particular, I focus my attention on explaining the \textbf{VILMA} functionalities: I will not mention what datasets the \textbf{VILMA} tests ware made on, but rather I will explain how it selects the foil-caption to carry out the tests. The report is structured as follows:

\textbf{Previous concepts:} concepts that are used in the report.

\textbf{Video Language Model Assessment:} I list models that will be evaluated by VILMA and I explain the VILMA tests.

\textbf{Pretrained models:} I list models evaluated by VILMA.

\textbf{Conclusions:} I observe several models on which the VILMA tests were applied, and I give a conclusion on VILMA benchmarks.




\end{abstract}

%\newpage 

\input{concepts}
\input{body}
\input{pretraining}
\input{conclusion}
\newpage
\input{bibliography}
\end{document}          
